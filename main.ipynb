{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 1. Importing the Data\n",
    "# -----------------------\n",
    "\n",
    "columns = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\",\n",
    "    \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\",\n",
    "    \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
    "    \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\",\n",
    "    \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\",\n",
    "    \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\",\n",
    "    \"label\", \"difficulty\"\n",
    "]\n",
    "\n",
    "# Load the training data.\n",
    "train_data = pd.read_csv(\"KDDTrain+.csv\", names=columns)\n",
    "train_data.drop(columns=['difficulty'], inplace=True)\n",
    "\n",
    "test_data = pd.read_csv(\"KDDTest+.csv\", names=columns)\n",
    "test_data.drop(columns=['difficulty'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  25   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  26   \n",
       "3               0       0    0  ...                 255   \n",
       "4               0       0    0  ...                 255   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.17                    0.03   \n",
       "1                    0.00                    0.60   \n",
       "2                    0.10                    0.05   \n",
       "3                    1.00                    0.00   \n",
       "4                    1.00                    0.00   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.17                         0.00   \n",
       "1                         0.88                         0.00   \n",
       "2                         0.00                         0.00   \n",
       "3                         0.03                         0.04   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.00                  0.05   \n",
       "1                  0.00                      0.00                  0.00   \n",
       "2                  1.00                      1.00                  0.00   \n",
       "3                  0.03                      0.01                  0.00   \n",
       "4                  0.00                      0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_rerror_rate    label  \n",
       "0                      0.00   normal  \n",
       "1                      0.00   normal  \n",
       "2                      0.00  neptune  \n",
       "3                      0.01   normal  \n",
       "4                      0.00   normal  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>12983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>eco_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>saint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>RSTO</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.71</td>\n",
       "      <td>mscan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp   private   REJ          0          0     0   \n",
       "1         0           tcp   private   REJ          0          0     0   \n",
       "2         2           tcp  ftp_data    SF      12983          0     0   \n",
       "3         0          icmp     eco_i    SF         20          0     0   \n",
       "4         1           tcp    telnet  RSTO          0         15     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  10   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  86   \n",
       "3               0       0    0  ...                  57   \n",
       "4               0       0    0  ...                  86   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.04                    0.06   \n",
       "1                    0.00                    0.06   \n",
       "2                    0.61                    0.04   \n",
       "3                    1.00                    0.00   \n",
       "4                    0.31                    0.17   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.00                         0.00   \n",
       "1                         0.00                         0.00   \n",
       "2                         0.61                         0.02   \n",
       "3                         1.00                         0.28   \n",
       "4                         0.03                         0.02   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                  1.00   \n",
       "1                   0.0                       0.0                  1.00   \n",
       "2                   0.0                       0.0                  0.00   \n",
       "3                   0.0                       0.0                  0.00   \n",
       "4                   0.0                       0.0                  0.83   \n",
       "\n",
       "   dst_host_srv_rerror_rate    label  \n",
       "0                      1.00  neptune  \n",
       "1                      1.00  neptune  \n",
       "2                      0.00   normal  \n",
       "3                      0.00    saint  \n",
       "4                      0.71    mscan  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 2. Preprocessing the Data\n",
    "# ------------------------------\n",
    "\n",
    "# Identify categorical columns.\n",
    "categorical_cols = [\"protocol_type\", \"service\", \"flag\"]\n",
    "\n",
    "# Apply one-hot encoding to the categorical columns for both train and test sets.\n",
    "train_data = pd.get_dummies(train_data, columns=categorical_cols)\n",
    "test_data = pd.get_dummies(test_data, columns=categorical_cols)\n",
    "\n",
    "# Separate features and labels.\n",
    "X_train = train_data.drop(columns=['label'])\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop(columns=['label'])\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Align the train and test feature sets so that they have the same columns.\n",
    "X_train, X_test = X_train.align(X_test, join='outer', axis=1, fill_value=0)\n",
    "\n",
    "# Convert the label to a binary outcome:\n",
    "#    - 0 for 'normal' (benign connections)\n",
    "#    - 1 for any attack type (malicious connections)\n",
    "y_train = y_train.apply(lambda x: 0 if x == 'normal' else 1)\n",
    "y_test = y_test.apply(lambda x: 0 if x == 'normal' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (125973, 122)\n",
      "Training labels shape: (125973,)\n",
      "Test features shape: (22543, 122)\n",
      "Test labels shape: (22543,)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 3. Verification of the Processed Data\n",
    "# ------------------------------\n",
    "\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Test features shape:\", X_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This scaler standardizes features by removing the mean and scaling to unit variance. Note that while scaling is especially important for models like SVMs or neural networks, many tree-based models (e.g., Random Forests) are less sensitive to feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled training features shape: (125973, 122)\n",
      "Scaled test features shape: (22543, 122)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it.\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Use the same scaler to transform the test data.\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Verify the shapes of the scaled features.\n",
    "print(\"Scaled training features shape:\", X_train_scaled.shape)\n",
    "print(\"Scaled test features shape:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet initializes the classifier, trains it on the scaled training set, makes predictions on the scaled test set, and then prints out performance metrics such as accuracy, the classification report, and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7755844386283991\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.97      0.79      9710\n",
      "           1       0.97      0.63      0.76     12833\n",
      "\n",
      "    accuracy                           0.78     22543\n",
      "   macro avg       0.82      0.80      0.77     22543\n",
      "weighted avg       0.84      0.78      0.77     22543\n",
      "\n",
      "Confusion Matrix:\n",
      " [[9458  252]\n",
      " [4807 8026]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the Random Forest classifier.\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the model on the scaled training data.\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data.\n",
    "y_pred = rf_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's performance.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~77.6% of the test samples were correctly classified. While accuracy gives a broad view, it’s especially important to consider class-specific metrics in cybersecurity applications where the cost of false negatives (missed attacks) can be high.\n",
    "\n",
    "For class 0 (\"normal\"):\n",
    "\n",
    "Recall: 0.97 indicates that nearly all benign connections are correctly identified.\n",
    "Precision: 0.66 suggests that when the model predicts \"normal,\" there's a substantial chance it might be a misclassified attack (i.e., some false negatives are getting labeled as normal).\n",
    "\n",
    "For class 1 (\"attack\"):\n",
    "\n",
    "Precision: 0.97 means that when the model flags a connection as an attack, it’s usually correct.\n",
    "Recall: 0.63 indicates that a significant number of attacks are being missed (i.e., false negatives are high).\n",
    "\n",
    "Now perform hyperparameter tuning on the Random Forest classifier using Scikit-learn’s GridSearchCV. In this example, we focus on optimizing for the recall of class 1 (attacks) by using a custom scorer. This is especially important in cybersecurity, where missing an attack (false negative) can have severe consequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Best Hyperparameters: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': None, 'class_weight': None}\n",
      "Best Cross-Validation Recall Score for Attack Class: 0.9985502317112344\n",
      "\n",
      "Test Accuracy after Randomized Search: 0.8002927738100519\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.81      9710\n",
      "           1       0.97      0.67      0.79     12833\n",
      "\n",
      "    accuracy                           0.80     22543\n",
      "   macro avg       0.83      0.82      0.80     22543\n",
      "weighted avg       0.85      0.80      0.80     22543\n",
      "\n",
      "Confusion Matrix:\n",
      " [[9417  293]\n",
      " [4209 8624]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Define a custom scorer to optimize for recall of class 1 (attacks).\n",
    "recall_scorer = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "# Define the same parameter grid.\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Initialize the base Random Forest classifier.\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Set up RandomizedSearchCV.\n",
    "random_search = RandomizedSearchCV(estimator=rf_clf,\n",
    "                                   param_distributions=param_grid,\n",
    "                                   n_iter=100,           # Number of random combinations to try\n",
    "                                   scoring=recall_scorer,  # Optimize for recall of the attack class\n",
    "                                   cv=3,                 # 3-fold cross-validation\n",
    "                                   n_jobs=-1,\n",
    "                                   verbose=3,\n",
    "                                   random_state=42)\n",
    "\n",
    "# Run the randomized search on the scaled training data.\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Output the best hyperparameters and best score.\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Validation Recall Score for Attack Class:\", random_search.best_score_)\n",
    "\n",
    "# Use the best estimator to make predictions on the test data.\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the tuned model on the test data.\n",
    "accuracy = best_rf.score(X_test_scaled, y_test)\n",
    "print(\"\\nTest Accuracy after Randomized Search:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_best))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold based on ROC: 0.0016666666666666668\n",
      "Adjusted Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      9710\n",
      "           1       0.92      0.90      0.91     12833\n",
      "\n",
      "    accuracy                           0.89     22543\n",
      "   macro avg       0.89      0.89      0.89     22543\n",
      "weighted avg       0.90      0.89      0.89     22543\n",
      "\n",
      "Adjusted Attack Recall: 0.8980752746824593\n",
      "\n",
      "Adjusted Confusion Matrix:\n",
      " [[ 8644  1066]\n",
      " [ 1308 11525]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, recall_score, classification_report\n",
    "\n",
    "# Get predicted probabilities for the positive class (attack)\n",
    "y_probs = best_rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs, pos_label=1)\n",
    "\n",
    "# Compute Youden's J statistic (tpr - fpr) for each threshold\n",
    "j_scores = tpr - fpr\n",
    "\n",
    "# Find the threshold that maximizes Youden's J statistic\n",
    "optimal_threshold = thresholds[np.argmax(j_scores)]\n",
    "print(\"Optimal threshold based on ROC:\", optimal_threshold)\n",
    "\n",
    "# Apply the new threshold to generate predictions\n",
    "y_pred_adjusted = (y_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate the adjusted predictions\n",
    "cm_tree_scaled = confusion_matrix(y_test, y_pred_adjusted)\n",
    "cf_tree_scaled = classification_report(y_test, y_pred_adjusted)\n",
    "print(\"Adjusted Classification Report:\\n\", cf_tree_scaled)\n",
    "print(\"Adjusted Attack Recall:\", recall_score(y_test, y_pred_adjusted))\n",
    "print(\"\\nAdjusted Confusion Matrix:\\n\", cm_tree_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost (Extreme Gradient Boosting)**\n",
    "\n",
    "XGBoost is renowned for its excellent predictive performance on structured/tabular data It’s highly optimized and can handle large datasets efficiently. Built-in regularization helps to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test Accuracy: 0.7919531561903917\n",
      "\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80      9710\n",
      "           1       0.97      0.66      0.78     12833\n",
      "\n",
      "    accuracy                           0.79     22543\n",
      "   macro avg       0.82      0.81      0.79     22543\n",
      "weighted avg       0.84      0.79      0.79     22543\n",
      "\n",
      "XGBoost Confusion Matrix:\n",
      " [[9439  271]\n",
      " [4419 8414]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize the XGBoost classifier.\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model on the scaled training data.\n",
    "xgb_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data.\n",
    "y_pred_xgb = xgb_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model.\n",
    "cm_xgboost_scaled = confusion_matrix(y_test, y_pred_xgb)\n",
    "cf_xgboost_scaled = classification_report(y_test, y_pred_xgb)\n",
    "print(\"XGBoost Test Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"\\nXGBoost Classification Report:\\n\", cf_xgboost_scaled)\n",
    "print(\"XGBoost Confusion Matrix:\\n\", cm_xgboost_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM**\n",
    "\n",
    "LightGBM is designed to be faster and more memory efficient than some other gradient boosting frameworks, which can be beneficial on larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 58630, number of negative: 67343\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3333\n",
      "[LightGBM] [Info] Number of data points in the train set: 125973, number of used features: 110\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.465417 -> initscore=-0.138552\n",
      "[LightGBM] [Info] Start training from score -0.138552\n",
      "LightGBM Test Accuracy: 0.783125582220645\n",
      "\n",
      "LightGBM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.97      0.79      9710\n",
      "           1       0.97      0.64      0.77     12833\n",
      "\n",
      "    accuracy                           0.78     22543\n",
      "   macro avg       0.82      0.81      0.78     22543\n",
      "weighted avg       0.84      0.78      0.78     22543\n",
      "\n",
      "LightGBM Confusion Matrix:\n",
      " [[9439  271]\n",
      " [4618 8215]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize the LightGBM classifier.\n",
    "lgb_clf = lgb.LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "lgb_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data.\n",
    "y_pred_lgb = lgb_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model.\n",
    "cm_lgb_scaled = confusion_matrix(y_test, y_pred_lgb)\n",
    "cf_lgb_scaled = classification_report(y_test, y_pred_lgb)\n",
    "print(\"LightGBM Test Accuracy:\", accuracy_score(y_test, y_pred_lgb))\n",
    "print(\"\\nLightGBM Classification Report:\\n\", cf_lgb_scaled)\n",
    "print(\"LightGBM Confusion Matrix:\\n\", cm_lgb_scaled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
